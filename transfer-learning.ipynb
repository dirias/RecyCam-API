{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "CHANNELS = 3\n",
    "NUM_EPOCHS = 5\n",
    "NUM_CLASS = 2\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MobileNetV2 from TensorFlow Hub\n",
    "base_model = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/procesadas/can/no_acceptable/imagen_1.jpg</td>\n",
       "      <td>no_aceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/procesadas/can/no_acceptable/imagen_2.jpg</td>\n",
       "      <td>no_aceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/procesadas/can/no_acceptable/imagen_3.jpg</td>\n",
       "      <td>no_aceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/procesadas/can/no_acceptable/imagen_4.jpg</td>\n",
       "      <td>no_aceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/procesadas/can/no_acceptable/imagen_5.jpg</td>\n",
       "      <td>no_aceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>./data/procesadas/plastic/acceptable/imagen_46...</td>\n",
       "      <td>aceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>./data/procesadas/plastic/acceptable/imagen_47...</td>\n",
       "      <td>aceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>./data/procesadas/plastic/acceptable/imagen_48...</td>\n",
       "      <td>aceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>./data/procesadas/plastic/acceptable/imagen_49...</td>\n",
       "      <td>aceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>./data/procesadas/plastic/acceptable/imagen_50...</td>\n",
       "      <td>aceptable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name      category\n",
       "0     ./data/procesadas/can/no_acceptable/imagen_1.jpg  no_aceptable\n",
       "1     ./data/procesadas/can/no_acceptable/imagen_2.jpg  no_aceptable\n",
       "2     ./data/procesadas/can/no_acceptable/imagen_3.jpg  no_aceptable\n",
       "3     ./data/procesadas/can/no_acceptable/imagen_4.jpg  no_aceptable\n",
       "4     ./data/procesadas/can/no_acceptable/imagen_5.jpg  no_aceptable\n",
       "..                                                 ...           ...\n",
       "195  ./data/procesadas/plastic/acceptable/imagen_46...     aceptable\n",
       "196  ./data/procesadas/plastic/acceptable/imagen_47...     aceptable\n",
       "197  ./data/procesadas/plastic/acceptable/imagen_48...     aceptable\n",
       "198  ./data/procesadas/plastic/acceptable/imagen_49...     aceptable\n",
       "199  ./data/procesadas/plastic/acceptable/imagen_50...     aceptable\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv('./data/working-table.csv')\n",
    "\n",
    "# Obtener las rutas de las imágenes y las etiquetas correspondientes\n",
    "#image_paths = ['./data/procesadas/' + name for name in df['name']]\n",
    "image_paths = df['name']\n",
    "labels = df['category']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot identify image file <_io.BytesIO object at 0x167a2a070>\n",
      "cannot identify image file <_io.BytesIO object at 0x167ad2cf0>\n",
      "cannot identify image file <_io.BytesIO object at 0x167b132e0>\n"
     ]
    }
   ],
   "source": [
    "# Process images and labels\n",
    "processed_images = []\n",
    "processed_labels = []\n",
    "\n",
    "for image_path, label in zip(df['name'], df['category']):\n",
    "    try:\n",
    "        try:\n",
    "            # Load the image\n",
    "            image = load_img(image_path, target_size=(HEIGHT, WIDTH))\n",
    "            # Convert the image to a NumPy array\n",
    "            image_array = img_to_array(image)\n",
    "            image_array = preprocess_input(image_array)  # Apply MobileNetV2-specific preprocessing\n",
    "            # Append the preprocessed image and label to the corresponding lists\n",
    "            processed_images.append(image_array)\n",
    "            \n",
    "            # Convert label to its corresponding numerical value\n",
    "            if \"no_aceptable\" in label:\n",
    "                processed_labels.append(0)\n",
    "            else:\n",
    "                processed_labels.append(1)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            continue\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        continue\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "processed_images = np.array(processed_images)\n",
    "processed_labels = np.array(processed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#processed_images\n",
    "processed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build fine-tuned model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASS, activation='softmax')  # Update to NUM_CLASS\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy for integer labels\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "\n",
    "datos_entrenamiento, datos_prueba, etiquetas_entrenamiento, etiquetas_prueba = train_test_split(\n",
    "    processed_images, processed_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5/5 [==============================] - 30s 3s/step - loss: 1.1374 - accuracy: 0.5287\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2859 - accuracy: 0.9363\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.1903 - accuracy: 0.9745\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.1662 - accuracy: 0.9936\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.1465 - accuracy: 0.9936\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning\n",
    "history = model.fit(datos_entrenamiento, etiquetas_entrenamiento,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 134ms/step - loss: 0.1676 - accuracy: 0.9750\n",
      "Pérdida: 0.16762223839759827\n",
      "Precisión: 0.9750000238418579\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "pérdida, precisión = model.evaluate(datos_prueba, etiquetas_prueba)\n",
    "print('Pérdida:', pérdida)\n",
    "print('Precisión:', precisión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 483ms/step\n",
      "F1-Score on Training Data: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions on the training data\n",
    "y_pred_entrenamiento = model.predict(datos_entrenamiento)\n",
    "\n",
    "# Calculate predicted probabilities for the positive class\n",
    "y_pred_entrenamiento_positive_class = y_pred_entrenamiento[:, 1]\n",
    "\n",
    "# Convert predicted probabilities to binary class labels\n",
    "y_pred_entrenamiento_binary = (y_pred_entrenamiento_positive_class > 0.5).astype(int)\n",
    "\n",
    "# Calculate F1-Score for training data\n",
    "f1_train = f1_score(etiquetas_entrenamiento, y_pred_entrenamiento_binary)\n",
    "\n",
    "print('F1-Score on Training Data:', f1_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "Formatted Predictions: ['0.99', '0.01']\n"
     ]
    }
   ],
   "source": [
    "# Probar el modelo\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "from PIL import Image\n",
    "\n",
    "# Ruta de la imagen que deseas utilizar para la predicción\n",
    "image_path = 'data/procesadas/can/no_acceptable/imagen_2.jpg'\n",
    "\n",
    "# Cargar la imagen\n",
    "image = Image.open(image_path)\n",
    "\n",
    "\n",
    "# Redimensionar la imagen a (HEIGHT, WIDTH)\n",
    "image = image.resize((WIDTH, HEIGHT))\n",
    "\n",
    "# Convertir la imagen a un array numpy y normalizar los valores de píxeles\n",
    "image_array = keras_image.img_to_array(image)\n",
    "image_array = image_array / 255.0\n",
    "\n",
    "# Agregar una dimensión extra para representar el batch (el modelo espera un lote de imágenes)\n",
    "input_data = np.expand_dims(image_array, axis=0)\n",
    "\n",
    "predictions = model.predict(input_data)\n",
    "\n",
    "# Format prediction probabilities to display 2 decimal places\n",
    "formatted_predictions = [format(prob, \".2f\") for prob in predictions[0]]\n",
    "\n",
    "# Print the formatted predictions\n",
    "print(\"Formatted Predictions:\", formatted_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbaltod1/Documents/UCenfotec/RecyCam-Model/venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('cnn_model_transfer_learning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
